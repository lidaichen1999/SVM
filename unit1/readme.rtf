{\rtf1\ansi\ansicpg936\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset134 PingFangSC-Regular;\f1\fswiss\fcharset0 Helvetica;\f2\froman\fcharset0 Times-Roman;
\f3\fnil\fcharset134 STSongti-SC-Regular;}
{\colortbl;\red255\green255\blue255;\red42\green49\blue64;\red245\green245\blue246;\red0\green0\blue0;
\red188\green188\blue188;\red151\green8\blue237;}
{\*\expandedcolortbl;;\cssrgb\c21569\c25490\c31765;\cssrgb\c96863\c96863\c97255;\cssrgb\c0\c0\c0;
\cssrgb\c78431\c78431\c78431;\cssrgb\c66667\c21569\c94510;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat0\levelspace360\levelindent0{\*\levelmarker \{none\}.}{\leveltext\leveltemplateid601\'01.;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid602\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat0\levelspace360\levelindent0{\*\levelmarker \{none\}.}{\leveltext\leveltemplateid801\'01.;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid11}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa400\partightenfactor0

\f0\fs32 \cf2 \cb3 \expnd0\expndtw0\kerning0
Q1\
\'ca\'e4\'b3\'f6\'b5\'c4\'b5\'da\'d2\'bb\'d5\'c5\'cd\'bcQ1-1\'ca\'c7\'ca\'fd\'be\'dd\'bc\'af\'b5\'c4\'c9\'a2\'b5\'e3\'cd\'bc\'a3\'ac\'c6\'e4\'d6\'d0\'ba\'ec\'c9\'ab\'d4\'b2\'c8\'a6\'b1\'ed\'ca\'be\'d5\'fd\'c0\'e0\'ca\'fd\'be\'dd\'a3\'ac\'c0\'b6\'c9\'ab\'d4\'b2\'c8\'a6\'b1\'ed\'ca\'be\'b8\'ba\'c0\'e0\'ca\'fd\'be\'dd\'a1\'a3\'b5\'da\'b6\'fe\'d5\'c5\'cd\'bcQ1-2\'ca\'c7\'b7\'d6\'c0\'e0\'c6\'f7\'cb\'f9\'b5\'c3\'b5\'bd\'b5\'c4\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'a3\'ac\'bc\'b4\'b7\'d6\'c0\'eb\'d5\'fd\'c0\'e0\'ba\'cd\'b8\'ba\'c0\'e0\'ca\'fd\'be\'dd\'b5\'c4\'cf\'df\'d0\'d4\'b1\'df\'bd\'e7\'a1\'a3
\f1 \cb1 \
\pard\pardeftab720\partightenfactor0

\f0 \cf2 \cb3 \'ce\'ca\'cc\'e2
\f1 \'93Obtain a line to classify the data by using what you know about the distributions of the data. In which sense is it optimal?\'94
\f0 \'b5\'c4\'b4\'f0\'b0\'b8\'bf\'c9\'d2\'d4\'b4\'d3\'b5\'da\'b6\'fe\'d5\'c5\'cd\'bc\'d6\'d0\'b5\'c3\'b5\'bd\'a1\'a3\'b8\'f9\'be\'dd\'ca\'fd\'be\'dd\'b5\'c4\'b7\'d6\'b2\'bc\'a3\'ac\'ce\'d2\'c3\'c7\'bf\'c9\'d2\'d4\'d1\'a1\'d4\'f1\'ca\'b9\'d3\'c3\'cf\'df\'d0\'d4\'b7\'d6\'c0\'e0\'c6\'f7\'c0\'b4\'b7\'d6\'c0\'eb\'d5\'fd\'c0\'e0\'ba\'cd\'b8\'ba\'c0\'e0\'ca\'fd\'be\'dd\'a1\'a3\'d4\'da\'d5\'e2\'b8\'f6\'c0\'fd\'d7\'d3\'d6\'d0\'a3\'ac\'ce\'d2\'c3\'c7\'bf\'c9\'d2\'d4\'ca\'b9\'d3\'c3\'b8\'d0\'d6\'aa\'c6\'f7\'cb\'e3\'b7\'a8\'b5\'c3\'b5\'bd\'d7\'ee\'d3\'c5\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'a3\'ac\'ca\'b9\'b5\'c3\'b7\'d6\'c0\'eb\'d5\'fd\'c0\'e0\'ba\'cd\'b8\'ba\'c0\'e0\'ca\'fd\'be\'dd\'b5\'c4\'ce\'f3\'b7\'d6\'c0\'e0\'b5\'e3\'d7\'ee\'c9\'d9\'a1\'a3\'d5\'e2\'b8\'f6\'cf\'df\'d0\'d4\'b7\'d6\'c0\'e0\'c6\'f7\'ca\'c7\'d7\'ee\'d3\'c5\'b5\'c4\'a3\'ac\'d2\'f2\'ce\'aa\'cb\'fc\'c4\'dc\'b9\'bb\'d5\'fd\'c8\'b7\'b5\'d8\'b7\'d6\'c0\'e0\'be\'a1\'bf\'c9\'c4\'dc\'b6\'e0\'b5\'c4\'ca\'fd\'be\'dd\'b5\'e3\'a3\'ac\'b2\'a2\'c7\'d2\'ce\'f3\'b7\'d6\'c0\'e0\'b5\'c4\'ca\'fd\'be\'dd\'b5\'e3\'ca\'fd\'c1\'bf\'d7\'ee\'c9\'d9\'a1\'a3\
\
Q2\
\'b5\'b1\'bd\'ab\'b8\'fc\'b6\'e0\'ca\'fd\'be\'dd\'b5\'e3\'cc\'ed\'bc\'d3\'b5\'bd\'ca\'fd\'be\'dd\'bc\'af\'ca\'b1\'a3\'ac\'c8\'e7\'b9\'fb\'d5\'e2\'d0\'a9\'ca\'fd\'be\'dd\'b5\'e3\'b1\'bb\'d5\'fd\'c8\'b7\'b7\'d6\'c0\'e0\'a3\'ac\'d4\'f2\'cb\'fc\'c3\'c7\'bd\'ab\'d4\'f6\'bc\'d3\'b6\'d4\'b7\'d6\'c0\'e0\'b3\'ac\'c6\'bd\'c3\'e6\'b5\'c4\'d6\'a7\'b3\'d6\'a3\'ac\'ca\'b9\'b5\'c3\'b7\'d6\'c0\'e0\'b3\'ac\'c6\'bd\'c3\'e6\'b8\'fc\'bc\'d3\'ce\'c8\'b6\'a8\'a1\'a3\'cf\'e0\'b7\'b4\'a3\'ac\'c8\'e7\'b9\'fb\'d5\'e2\'d0\'a9\'ca\'fd\'be\'dd\'b5\'e3\'b1\'bb\'b4\'ed\'ce\'f3\'b7\'d6\'c0\'e0\'a3\'ac\'d4\'f2\'cb\'fc\'c3\'c7\'bd\'ab\'b6\'d4\'b7\'d6\'c0\'e0\'b3\'ac\'c6\'bd\'c3\'e6\'b5\'c4\'ce\'bb\'d6\'c3\'b2\'fa\'c9\'fa\'d3\'b0\'cf\'ec\'a3\'ac\'b2\'a2\'bf\'c9\'c4\'dc\'b5\'bc\'d6\'c2\'b7\'d6\'c0\'e0\'b3\'ac\'c6\'bd\'c3\'e6\'b5\'c4\'c6\'ab\'d2\'c6\'bb\'f2\'b4\'ed\'ce\'f3\'b7\'d6\'c0\'e0\'a1\'a3\'d4\'da\'d5\'e2\'b8\'f6\'d4\'da\'cf\'df\'d3\'a6\'d3\'c3\'b3\'cc\'d0\'f2\'d6\'d0\'a3\'ac\'ce\'d2\'c3\'c7\'bf\'c9\'d2\'d4\'cd\'a8\'b9\'fd\'b8\'c4\'b1\'e4\'d5\'fd\'d4\'f2\'bb\'af\'b3\'ac\'b2\'ce\'ca\'fd
\f1 C
\f0 \'ba\'cd\'ba\'cb\'b2\'ce\'ca\'fd
\f1 sigma
\f0 \'b5\'c4\'d6\'b5\'c0\'b4\'b8\'c4\'b1\'e4\'b7\'d6\'c0\'e0\'bd\'e1\'b9\'fb\'a1\'a3\'d5\'fd\'d4\'f2\'bb\'af\'b3\'ac\'b2\'ce\'ca\'fd
\f1 C
\f0 \'ca\'c7\'d2\'bb\'b8\'f6\'b7\'c7\'b8\'ba\'b2\'ce\'ca\'fd\'a3\'ac\'cb\'fc\'bf\'d8\'d6\'c6\'c1\'cb\'b7\'d6\'c0\'e0\'c6\'f7\'d4\'da\'b7\'d6\'c0\'e0\'b4\'ed\'ce\'f3\'ba\'cd\'b1\'a3\'b3\'d6\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'d6\'ae\'bc\'e4\'b5\'c4\'c6\'bd\'ba\'e2\'a1\'a3\'bd\'cf\'b4\'f3\'b5\'c4
\f1 C
\f0 \'d6\'b5\'bb\'e1\'b5\'bc\'d6\'c2\'b8\'fc\'c9\'d9\'b5\'c4\'b4\'ed\'ce\'f3\'b7\'d6\'c0\'e0\'a3\'ac\'b5\'ab\'bf\'c9\'c4\'dc\'bb\'e1\'b5\'bc\'d6\'c2\'b9\'fd\'b6\'c8\'c4\'e2\'ba\'cf\'a1\'a3\'bd\'cf\'d0\'a1\'b5\'c4
\f1 C
\f0 \'d6\'b5\'d4\'f2\'bb\'e1\'b5\'bc\'d6\'c2\'b8\'fc\'b6\'e0\'b5\'c4\'b4\'ed\'ce\'f3\'b7\'d6\'c0\'e0\'a3\'ac\'b5\'ab\'bf\'c9\'c4\'dc\'bb\'e1\'b2\'fa\'c9\'fa\'b8\'fc\'b9\'e3\'b7\'ba\'b5\'c4\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'a1\'a3\'ba\'cb\'b2\'ce\'ca\'fd
\f1 sigma
\f0 \'d3\'c3\'d3\'da\'b5\'f7\'d5\'fb
\f1 RBF
\f0 \'ba\'cb\'b5\'c4\'d0\'ce\'d7\'b4\'a3\'ac\'bd\'cf\'b4\'f3\'b5\'c4
\f1 sigma
\f0 \'d6\'b5\'bb\'e1\'b5\'bc\'d6\'c2\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'b8\'fc\'bc\'d3\'c6\'bd\'bb\'ac\'a3\'ac\'bd\'cf\'d0\'a1\'b5\'c4
\f1 sigma
\f0 \'d6\'b5\'d4\'f2\'bb\'e1\'b5\'bc\'d6\'c2\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'b8\'fc\'bc\'d3\'c8\'f1\'c0\'fb\'a1\'a3\'d4\'da\'ca\'b5\'bc\'f9\'d6\'d0\'a3\'ac\'d5\'e2\'d0\'a9\'b2\'ce\'ca\'fd\'b5\'c4\'d7\'ee\'bc\'d1\'d6\'b5\'c8\'a1\'be\'f6\'d3\'da\'be\'df\'cc\'e5\'ce\'ca\'cc\'e2\'ba\'cd\'ca\'fd\'be\'dd\'bc\'af\'a3\'ac\'d0\'e8\'d2\'aa\'cd\'a8\'b9\'fd\'ca\'b5\'d1\'e9\'c0\'b4\'c8\'b7\'b6\'a8\'a1\'a3\'b5\'b1\'ce\'d2\'c3\'c7\'b1\'c8\'bd\'cf\'ca\'b9\'d3\'c3\'cf\'df\'d0\'d4\'ba\'cb\'ba\'cd
\f1 RBF
\f0 \'ba\'cb\'bd\'f8\'d0\'d0\'b7\'d6\'c0\'e0\'ca\'b1\'a3\'ac\'cd\'a8\'b3\'a3\'c7\'e9\'bf\'f6\'cf\'c2\'a3\'ac
\f1 RBF
\f0 \'ba\'cb\'bf\'c9\'d2\'d4\'b4\'a6\'c0\'ed\'b8\'fc\'ce\'aa\'b8\'b4\'d4\'d3\'b5\'c4\'b7\'c7\'cf\'df\'d0\'d4\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'a3\'ac\'d2\'f2\'b4\'cb\'d4\'da\'b4\'a6\'c0\'ed\'b7\'c7\'cf\'df\'d0\'d4\'ce\'ca\'cc\'e2\'ca\'b1\'b1\'ed\'cf\'d6\'b8\'fc\'ba\'c3\'a1\'a3\
\'b5\'b1\'ce\'d2\'c3\'c7\'cc\'ed\'bc\'d3\'b8\'fc\'b6\'e0\'ca\'fd\'be\'dd\'b5\'e3\'b5\'bd\'ca\'fd\'be\'dd\'bc\'af\'ca\'b1\'a3\'ac\'ce\'d2\'c3\'c7\'bf\'c9\'d2\'d4\'bf\'b4\'b5\'bd\'b7\'d6\'c0\'e0\'b3\'ac\'c6\'bd\'c3\'e6\'d4\'da\'be\'a1\'bf\'c9\'c4\'dc\'b5\'d8\'bd\'ab\'ca\'fd\'be\'dd\'b5\'e3\'d5\'fd\'c8\'b7\'b5\'d8\'b7\'d6\'bf\'aa\'a1\'a3\'d2\'bb\'d0\'a9\'ca\'fd\'be\'dd\'b5\'e3\'b3\'c9\'ce\'aa\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'a3\'ac\'d5\'e2\'d0\'a9\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'ca\'c7\'d7\'ee\'bf\'bf\'bd\'fc\'b7\'d6\'c0\'e0\'b1\'df\'bd\'e7\'b5\'c4\'b5\'e3\'a3\'ac\'d5\'e2\'d0\'a9\'b5\'e3\'b5\'c4\'ce\'bb\'d6\'c3\'ba\'cd\'ca\'fd\'c1\'bf\'bb\'e1\'d3\'b0\'cf\'ec\'b7\'d6\'c0\'e0\'b3\'ac\'c6\'bd\'c3\'e6\'b5\'c4\'ce\'bb\'d6\'c3\'ba\'cd\'d0\'ce\'d7\'b4\'a1\'a3\'b5\'b1\'ce\'d2\'c3\'c7\'b8\'c4\'b1\'e4\'d5\'fd\'d4\'f2\'bb\'af\'b2\'ce\'ca\'fd
\f1 C
\f0 \'ba\'cd\'ba\'cb\'b2\'ce\'ca\'fd
\f1 sigma
\f0 \'ca\'b1\'a3\'ac\'ce\'d2\'c3\'c7\'bf\'c9\'d2\'d4\'bf\'b4\'b5\'bd\'cb\'fc\'c3\'c7\'b6\'d4\'b7\'d6\'c0\'e0\'bd\'e1\'b9\'fb\'b5\'c4\'d3\'b0\'cf\'ec\'a1\'a3\'d4\'da\'d2\'bb\'b6\'a8\'b7\'b6\'ce\'a7\'c4\'da\'a3\'ac\'ca\'ca\'b5\'b1\'b5\'c4\'b2\'ce\'ca\'fd\'d1\'a1\'d4\'f1\'bf\'c9\'d2\'d4\'ca\'b9\'b7\'d6\'c0\'e0\'b3\'ac\'c6\'bd\'c3\'e6\'b8\'fc\'ba\'c3\'b5\'d8\'b7\'d6\'bf\'aa\'ca\'fd\'be\'dd\'b5\'e3\'a3\'ac\'b6\'f8\'b2\'bb\'ba\'cf\'ca\'ca\'b5\'c4\'b2\'ce\'ca\'fd\'d1\'a1\'d4\'f1\'bb\'e1\'b5\'bc\'d6\'c2\'b7\'d6\'c0\'e0\'b4\'ed\'ce\'f3\'a1\'a3\'b5\'b1
\f1 sigma
\f0 \'b7\'c7\'b3\'a3\'b4\'f3\'ca\'b1\'a3\'ac\'b7\'d6\'c0\'e0\'b1\'df\'bd\'e7\'bb\'e1\'b1\'e4\'b5\'c3\'b7\'c7\'b3\'a3\'c6\'bd\'bb\'ac\'a3\'ac\'d2\'f2\'ce\'aa
\f1 RBF
\f0 \'ba\'cb\'ba\'af\'ca\'fd\'b6\'d4\'be\'e0\'c0\'eb\'bd\'cf\'d4\'b6\'b5\'c4\'b5\'e3\'b8\'b3\'d3\'e8\'c1\'cb\'b7\'c7\'b3\'a3\'d0\'a1\'b5\'c4\'c8\'a8\'d6\'d8\'a3\'ac\'ca\'b9\'b5\'c3\'d5\'e2\'d0\'a9\'b5\'e3\'b6\'d4\'b7\'d6\'c0\'e0\'be\'f6\'b2\'df\'bc\'b8\'ba\'f5\'c3\'bb\'d3\'d0\'d3\'b0\'cf\'ec\'a1\'a3\
\
\'ce\'ca\'cc\'e2\'a3\'ba
\f1 \kerning1\expnd0\expndtw0 	1	
\f0 \expnd0\expndtw0\kerning0
\'ca\'b2\'c3\'b4\'ca\'c7\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'a3\'bf\'ba\'ce\'ca\'b1\'cc\'d8\'b6\'a8\'ca\'fd\'be\'dd\'b5\'e3\'b3\'c9\'ce\'aa\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'a3\'bf\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'b5\'c4\'d6\'d8\'d2\'aa\'d0\'d4\'ba\'ce\'ca\'b1\'b8\'c4\'b1\'e4\'a3\'bf\'cd\'a8\'b9\'fd\'bf\'c9\'ca\'d3\'bb\'af\'bd\'f8\'d0\'d0\'cb\'b5\'c3\'f7\'a1\'a3\'c7\'eb\'d7\'a2\'d2\'e2\'a3\'ac\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'d3\'c9\'b4\'f8\'b4\'d6\'cf\'df\'b5\'c4\'b4\'f3\'d4\'b2\'b1\'ed\'ca\'be\'a3\'ac\'c6\'e4\'d6\'d8\'d2\'aa\'d0\'d4\'d3\'eb\'d4\'da\'cf\'df\'d3\'a6\'d3\'c3\'b3\'cc\'d0\'f2\'d6\'d0\'b5\'c4\'b4\'f3\'d0\'a1\'b3\'c9\'b1\'c8\'c0\'fd\'a1\'a3
\f1 \cb1 \uc0\u8232 
\f0 \cb3 \'b4\'f0\'a3\'ba\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'ca\'c7\'d1\'b5\'c1\'b7
\f1 SVM
\f0 \'ca\'b1\'ca\'b9\'d3\'c3\'b5\'c4\'d1\'b5\'c1\'b7\'d1\'f9\'b1\'be\'ca\'fd\'be\'dd\'b5\'e3\'a1\'a3\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'ca\'c7\'ce\'bb\'d3\'da\'b3\'ac\'c6\'bd\'c3\'e6\'d7\'ee\'bf\'bf\'bd\'fc\'b1\'df\'bd\'e7\'b5\'c4\'ca\'fd\'be\'dd\'b5\'e3\'a1\'a3\'d4\'da\'b7\'d6\'c0\'e0\'c6\'f7\'d6\'d0\'a3\'ac\'b5\'b1\'b6\'d4\'d0\'c2\'b5\'c4\'ca\'fd\'be\'dd\'b5\'e3\'bd\'f8\'d0\'d0\'b7\'d6\'c0\'e0\'ca\'b1\'a3\'ac\'d6\'bb\'d3\'d0\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'b6\'d4\'b7\'d6\'c0\'e0\'bd\'e1\'b9\'fb\'d3\'d0\'b9\'b1\'cf\'d7\'a1\'a3\'b5\'b1\'ca\'fd\'be\'dd\'b5\'e3\'b1\'bb\'b5\'f7\'d5\'fb\'bb\'f2\'cc\'ed\'bc\'d3\'b5\'bd\'ca\'fd\'be\'dd\'bc\'af\'d6\'d0\'ca\'b1\'a3\'ac\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'b5\'c4\'ce\'bb\'d6\'c3\'ba\'cd\'ca\'fd\'c1\'bf\'bf\'c9\'c4\'dc\'bb\'e1\'b7\'a2\'c9\'fa\'b1\'e4\'bb\'af\'a3\'ac\'c6\'e4\'d6\'d8\'d2\'aa\'d0\'d4\'d2\'b2\'bf\'c9\'c4\'dc\'cb\'e6\'d6\'ae\'b1\'e4\'bb\'af\'a1\'a3\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'d6\'d8\'d2\'aa\'d0\'d4\'b4\'f3\'d0\'a1\'ca\'c7\'d3\'c9\'d4\'da\'cf\'df\'d3\'a6\'d3\'c3\'b3\'cc\'d0\'f2\'d6\'d0\'b4\'f3\'d4\'b2\'b5\'c4\'b4\'f3\'d0\'a1\'b1\'ed\'ca\'be\'b5\'c4\'a1\'a3
\f1 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	1	}
\f0 \expnd0\expndtw0\kerning0
\'b2\'ce\'ca\'fd
\f1 C
\f0 \'ba\'cd
\f1 sigma
\f0 \'b5\'c4\'d7\'f7\'d3\'c3\'ca\'c7\'ca\'b2\'c3\'b4\'a3\'bf\'c8\'e7\'b9\'fb\'b8\'c4\'b1\'e4\'d5\'e2\'d0\'a9\'b2\'ce\'ca\'fd\'a3\'ac\'b7\'d6\'c0\'e0\'b1\'df\'bd\'e7\'bb\'e1\'b7\'a2\'c9\'fa\'ca\'b2\'c3\'b4\'b1\'e4\'bb\'af\'a3\'bf\'cd\'a8\'b9\'fd\'bf\'c9\'ca\'d3\'bb\'af\'bd\'f8\'d0\'d0\'cb\'b5\'c3\'f7\'a1\'a3
\f1 \cb1 \uc0\u8232 
\f0 \cb3 \'b4\'f0\'a3\'ba\'b2\'ce\'ca\'fd
\f1 C
\f0 \'ca\'c7
\f1 SVM
\f0 \'b5\'c4\'d5\'fd\'d4\'f2\'bb\'af\'b2\'ce\'ca\'fd\'a3\'ac\'cb\'fc\'bf\'d8\'d6\'c6\'b7\'d6\'c0\'e0\'c6\'f7\'b5\'c4\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'b6\'d4\'d1\'b5\'c1\'b7\'d1\'f9\'b1\'be\'b5\'c4\'c4\'e2\'ba\'cf\'b3\'cc\'b6\'c8\'ba\'cd\'b6\'d4\'ce\'f3\'b7\'d6\'c0\'e0\'b5\'e3\'b5\'c4\'c8\'dd\'c8\'cc\'b6\'c8\'a1\'a3\'bd\'cf\'d0\'a1\'b5\'c4
\f1 C
\f0 \'d6\'b5\'d4\'ca\'d0\'ed\'b8\'fc\'b6\'e0\'b5\'c4\'ce\'f3\'b7\'d6\'c0\'e0\'b5\'e3\'a3\'ac\'b8\'fc\'b4\'f3\'b5\'c4
\f1 C
\f0 \'d6\'b5\'bb\'e1\'b5\'bc\'d6\'c2\'b7\'d6\'c0\'e0\'c6\'f7\'b3\'a2\'ca\'d4\'b8\'fc\'ba\'c3\'b5\'d8\'c4\'e2\'ba\'cf\'d1\'b5\'c1\'b7\'d1\'f9\'b1\'be\'a1\'a3\'b2\'ce\'ca\'fd
\f1 sigma
\f0 \'ca\'c7\'be\'b6\'cf\'f2\'bb\'f9\'ba\'af\'ca\'fd\'a3\'a8
\f1 RBF
\f0 \'a3\'a9\'ba\'cb\'ba\'af\'ca\'fd\'b5\'c4\'b4\'f8\'bf\'ed\'b2\'ce\'ca\'fd\'a3\'ac\'bf\'d8\'d6\'c6
\f1 RBF
\f0 \'ba\'cb\'ba\'af\'ca\'fd\'b5\'c4\'bf\'ed\'b6\'c8\'a1\'a3\'bd\'cf\'d0\'a1\'b5\'c4
\f1 sigma
\f0 \'d6\'b5\'bb\'e1\'b5\'bc\'d6\'c2\'b8\'df\'cb\'b9\'ba\'cb\'ba\'af\'ca\'fd\'b8\'fc\'bc\'d3\'d5\'ad\'a3\'ac\'d5\'e2\'bb\'e1\'b5\'bc\'d6\'c2\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'b8\'fc\'bc\'d3\'c7\'bf\'b5\'f7\'b5\'a5\'b8\'f6\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'a3\'ac\'b6\'f8\'bd\'cf\'b4\'f3\'b5\'c4
\f1 sigma
\f0 \'d6\'b5\'bb\'e1\'ca\'b9\'b8\'df\'cb\'b9\'ba\'cb\'ba\'af\'ca\'fd\'b8\'fc\'bc\'d3\'c6\'bd\'bb\'ba\'a3\'ac\'be\'f6\'b2\'df\'b1\'df\'bd\'e7\'d4\'f2\'b8\'fc\'bc\'d3\'c6\'bd\'bb\'ac\'a1\'a3
\f1 \cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	2	}
\f0 \expnd0\expndtw0\kerning0
\'b5\'b1
\f1 sigma
\f0 \'c8\'a1\'b7\'c7\'b3\'a3\'b4\'f3\'b5\'c4\'d6\'b5\'ca\'b1\'a3\'ac\'b7\'d6\'c0\'e0\'b1\'df\'bd\'e7\'bb\'e1\'b7\'a2\'c9\'fa\'ca\'b2\'c3\'b4\'b1\'e4\'bb\'af\'a3\'bf\'ce\'aa\'ca\'b2\'c3\'b4\'a3\'bf
\f1 \cb1 \uc0\u8232 
\f0 \cb3 \'b4\'f0\'a3\'ba\'b5\'b1
\f1 sigma
\f0 \'c8\'a1\'b7\'c7\'b3\'a3\'b4\'f3\'b5\'c4\'d6\'b5\'ca\'b1\'a3\'ac\'b8\'df\'cb\'b9\'ba\'cb\'ba\'af\'ca\'fd\'bb\'e1\'b1\'e4\'b5\'c3\'b7\'c7\'b3\'a3\'c6\'bd\'cc\'b9\'a3\'ac\'cf\'e0\'b5\'b1\'d3\'da\'bd\'fc\'cb\'c6\'d3\'da\'cf\'df\'d0\'d4\'ba\'cb\'ba\'af\'ca\'fd\'a1\'a3\'d5\'e2\'bb\'e1\'b5\'bc\'d6\'c2\'b7\'d6\'c0\'e0\'c6\'f7\'b1\'e4\'b5\'c3\'b9\'fd\'d3\'da\'b8\'b4\'d4\'d3\'a3\'ac\'b6\'d4\'d4\'eb\'c9\'f9\'ba\'cd\'d2\'ec\'b3\'a3\'d6\'b5\'b5\'c4\'c3\'f4\'b8\'d0\'d0\'d4\'d4\'f6\'bc\'d3\'a3\'ac\'b4\'d3\'b6\'f8\'bf\'c9\'c4\'dc\'b5\'bc\'d6\'c2\'b9\'fd\'c4\'e2\'ba\'cf\'b5\'c4\'ce\'ca\'cc\'e2\'a1\'a3\'b4\'cb\'cd\'e2\'a3\'ac\'b5\'b1
\f1 sigma
\f0 \'d6\'b5\'b7\'c7\'b3\'a3\'b4\'f3\'ca\'b1\'a3\'ac\'ca\'fd\'be\'dd\'b5\'e3\'d6\'ae\'bc\'e4\'b5\'c4\'be\'e0\'c0\'eb\'b1\'e4\'b5\'c3\'cf\'e0\'b6\'d4\'bd\'cf\'d0\'a1\'a3\'ac\'d5\'e2\'bb\'e1\'ca\'b9\'b7\'d6\'c0\'e0\'c6\'f7\'b8\'fc\'bc\'d3\'b9\'d8\'d7\'a2\'b5\'a5\'b8\'f6\'d6\'a7\'b3\'d6\'cf\'f2\'c1\'bf\'a3\'ac\'b6\'f8\'b2\'bb\'ca\'c7\'d5\'fb\'b8\'f6\'ca\'fd\'be\'dd\'b7\'d6\'b2\'bc\'a1\'a3\
\pard\tx566\pardeftab720\partightenfactor0
\cf2 \
\
Q3\
\pard\pardeftab720\sa400\partightenfactor0

\f1 \cf2 To answer the questions:\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
For the polynomial kernel with degree = 1, 2, 3, ..., and t = 1 (fix gam = 1), we can assess the performance on the test set by plotting the accuracy of the SVM model against the degree of the polynomial kernel. The plot should show how the accuracy changes as the degree of the polynomial kernel increases. Based on the plot, we can see how the performance changes when we change the degree of the polynomial kernel.\
For the polynomial kernel with varying degrees, we can look at the plot titled "Performance of SVM with polynomial kernel". The x-axis shows the polynomial degree, and the y-axis shows the accuracy of the SVM model.\
\pard\tx566\pardeftab720\partightenfactor0
\cf2 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
For the RBF kernel with squared kernel bandwidth \uc0\u963 2, we can try out a good range of different sig2 values as kernel parameters (fix gam = 1) and assess the performance on the test set. We can plot the accuracy of the SVM model against the squared kernel bandwidth \u963 2 (using a log scale) to see how the performance changes as we vary the \u963 2 parameter. Based on the plot, we can determine what is a good range for the \u963 2 parameter.\
For the RBF kernel with varying squared kernel bandwidths, we can look at the plot titled "Performance of SVM with RBF kernel". The x-axis shows the squared kernel bandwidth (using a log scale), and the y-axis shows the accuracy of the SVM model.\
\pard\tx566\pardeftab720\partightenfactor0
\cf2 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	1	}\expnd0\expndtw0\kerning0
For the RBF kernel with fixed squared kernel bandwidth and varying regularization constants, we can fix a reasonable choice for the \uc0\u963 2 parameter and compare the performance using a range of gam values. We can plot the accuracy of the SVM model against the regularization constant gam (using a log scale) to see how the performance changes as we vary the gam parameter. Based on the plot, we can determine what is a good range for the gam parameter.For the RBF kernel with fixed squared kernel bandwidth and varying regularization constants, we can look at the plot titled "Performance of SVM with RBF kernel". The x-axis shows the regularization constant (using a log scale), and the y-axis shows the accuracy of the SVM model.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0
\f0 \cf2 \cb3 \
\pard\pardeftab720\sa400\partightenfactor0

\f1 \cf2 \cb1 \
\pard\pardeftab720\sa240\partightenfactor0

\f2\fs26\fsmilli13333 \cf4 1.3.1 Influence of hyperparameters and kernel parameters 
\f1\fs32 \cf2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa266\partightenfactor0
\ls6\ilvl0
\f2\fs26\fsmilli13333 \cf4 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Try out a polynomial kernel with degree = 1,2,3,... and t = 1 (fix gam = 1). Assess the performance on the test set. What happens when you change the degree of the polynomial kernel? 
\f1\fs32 \cf2 \
\pard\pardeftab720\sa400\partightenfactor0
\cf2 0.2500    0.5000       NaN\
    0.5000    1.0000    1.8182\
    0.4750    0.9500    1.7273\
    0.4500    0.9000    1.6364\
    0.4250    0.8500    1.5455\
    0.3750    0.7500    1.3636\
\
Best model performance:\
Accuracy: 0.50\
Recall: 1.00\
F1 score: 1.82\

\f0 \cb3 \'d5\'e2\'b8\'f6\'bd\'e1\'b9\'fb\'d2\'e2\'ce\'b6\'d7\'c5\'c4\'fa\'d4\'da\'b6\'e0\'cf\'ee\'ca\'bd\'ba\'cb\'c9\'cf\'b3\'a2\'ca\'d4\'c1\'cb\'b4\'d3
\f1 1
\f0 \'b5\'bd
\f1 6
\f0 \'b5\'c4\'b2\'bb\'cd\'ac\'b6\'c8\'ca\'fd\'a3\'ac\'b2\'a2\'c6\'c0\'b9\'c0\'c1\'cb\'c3\'bf\'b8\'f6\'b6\'c8\'ca\'fd\'b5\'c4\'d0\'d4\'c4\'dc\'a1\'a3\'c3\'bf\'d0\'d0\'b1\'ed\'ca\'be\'d2\'bb\'b8\'f6\'b6\'e0\'cf\'ee\'ca\'bd\'ba\'cb\'b6\'c8\'ca\'fd\'a3\'ac\'c3\'bf\'c1\'d0\'b1\'ed\'ca\'be\'d0\'d4\'c4\'dc\'b6\'c8\'c1\'bf\'a3\'ac\'c6\'e4\'d6\'d0\'b5\'da\'d2\'bb\'c1\'d0\'ca\'c7\'d7\'bc\'c8\'b7\'b6\'c8\'a3\'ac\'b5\'da\'b6\'fe\'c1\'d0\'ca\'c7\'d5\'d9\'bb\'d8\'c2\'ca\'a3\'ac\'b5\'da\'c8\'fd\'c1\'d0\'ca\'c7
\f1 F1
\f0 \'b7\'d6\'ca\'fd\'a1\'a3\'b6\'d4\'d3\'da\'b5\'da\'d2\'bb\'b8\'f6\'b6\'c8\'ca\'fd\'a3\'ac\'c4\'a3\'d0\'cd\'b5\'c4\'d7\'bc\'c8\'b7\'b6\'c8\'ce\'aa
\f1 0.25
\f0 \'a3\'ac\'d5\'d9\'bb\'d8\'c2\'ca\'ce\'aa
\f1 0.5
\f0 \'a3\'ac
\f1 F1
\f0 \'b7\'d6\'ca\'fd\'ce\'aa
\f1 NaN
\f0 \'a3\'a8\'b2\'bb\'ca\'c7\'d2\'bb\'b8\'f6\'ca\'fd\'d7\'d6\'a3\'ac\'b1\'ed\'ca\'be\'ce\'de\'b7\'a8\'bc\'c6\'cb\'e3\'a3\'a9\'a1\'a3\'cb\'e6\'d7\'c5\'b6\'c8\'ca\'fd\'b5\'c4\'d4\'f6\'bc\'d3\'a3\'ac\'d7\'bc\'c8\'b7\'b6\'c8\'ba\'cd\'d5\'d9\'bb\'d8\'c2\'ca\'b6\'bc\'d3\'d0\'cb\'f9\'cc\'e1\'b8\'df\'a3\'ac\'b6\'f8
\f1 F1
\f0 \'b7\'d6\'ca\'fd\'d4\'f2\'d4\'da\'c4\'b3\'d0\'a9\'b6\'c8\'ca\'fd\'c9\'cf\'b3\'f6\'cf\'d6\'c1\'cb\'b7\'e5\'d6\'b5\'a1\'a3
\f1 \cb1 \
\pard\pardeftab720\partightenfactor0

\f0 \cf2 \cb3 \'d4\'da\'d5\'e2\'b8\'f6\'bd\'e1\'b9\'fb\'d6\'d0\'a3\'ac\'d7\'ee\'ba\'c3\'b5\'c4\'d0\'d4\'c4\'dc\'c4\'a3\'d0\'cd\'ca\'c7\'b6\'e0\'cf\'ee\'ca\'bd\'ba\'cb\'b6\'c8\'ca\'fd\'ce\'aa
\f1 2
\f0 \'b5\'c4\'c4\'a3\'d0\'cd\'a3\'ac\'cb\'fc\'be\'df\'d3\'d0
\f1 50
\f0 \'a3\'a5\'b5\'c4\'d7\'bc\'c8\'b7\'b6\'c8\'a3\'ac
\f1 100
\f0 \'a3\'a5\'b5\'c4\'d5\'d9\'bb\'d8\'c2\'ca\'ba\'cd
\f1 1.82
\f0 \'b5\'c4
\f1 F1
\f0 \'b7\'d6\'ca\'fd\'a1\'a3\'d5\'e2\'d2\'e2\'ce\'b6\'d7\'c5\'ca\'b9\'d3\'c3\'b6\'e0\'cf\'ee\'ca\'bd\'ba\'cb\'b6\'c8\'ca\'fd\'ce\'aa
\f1 2
\f0 \'b5\'c4
\f1 SVM
\f0 \'c4\'a3\'d0\'cd\'bf\'c9\'d2\'d4\'b6\'d4\'ca\'fd\'be\'dd\'bd\'f8\'d0\'d0\'b7\'c7\'b3\'a3\'d7\'bc\'c8\'b7\'b5\'c4\'b7\'d6\'c0\'e0\'a3\'ac\'b2\'a2\'c7\'d2\'c4\'dc\'b9\'bb\'b2\'b6\'d7\'bd\'b5\'bd\'d5\'fd\'c0\'fd\'c0\'e0\'b1\'f0\'b5\'c4\'b4\'f3\'b2\'bf\'b7\'d6\'ca\'b5\'c0\'fd\'a1\'a3\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls7\ilvl0
\f2\fs26\fsmilli13333 \cf4 \cb5 \kerning1\expnd0\expndtw0 {\listtext	.	}\expnd0\expndtw0\kerning0
Questions 
\fs24 \cb1 \uc0\u8232 \
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sa266\partightenfactor0
\ls7\ilvl1
\fs26\fsmilli13333 \cf4 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Compute the performance for a range of gam and sig2 values (e.g., \uc0\u947 ,\u963 
\fs18\fsmilli9333 \up10 2 
\fs26\fsmilli13333 \up0 = 10
\fs18\fsmilli9333 \up10 \uc0\u8722 3
\fs26\fsmilli13333 \up0 , . . . , 10
\fs18\fsmilli9333 \up10 3
\fs26\fsmilli13333 \up0 ). Use the random split method, 10-fold crossvalidation and leave-one-out validation. Visualize the results of each method: do you observe differences? Interpret the results: which values of gam and sig2 would you choose? \uc0\u8232 \
\pard\pardeftab720\partightenfactor0

\f0\fs32 \cf2 \cb3 \
\'d5\'e2\'b6\'ce\'b4\'fa\'c2\'eb\'c9\'fa\'b3\'c9\'c1\'cb\'d2\'bb\'b8\'f6\'b0\'fc\'ba\'ac\'c8\'fd\'b8\'f6\'d7\'d3\'cd\'bc\'b5\'c4\'cd\'bc\'b1\'ed\'a3\'ac\'c3\'bf\'b8\'f6\'d7\'d3\'cd\'bc\'cf\'d4\'ca\'be\'c1\'cb\'d2\'bb\'b8\'f6\'b2\'bb\'cd\'ac\'b5\'c4\'bd\'bb\'b2\'e6\'d1\'e9\'d6\'a4\'b7\'bd\'b7\'a8\'a3\'a8\'cb\'e6\'bb\'fa\'b7\'d6\'b8\'ee\'a3\'ac
\f1 10
\f0 \'d5\'db\'bd\'bb\'b2\'e6\'d1\'e9\'d6\'a4\'ba\'cd\'c1\'f4\'d2\'bb\'bd\'bb\'b2\'e6\'d1\'e9\'d6\'a4\'a3\'a9\'b5\'c4\'bd\'e1\'b9\'fb\'a1\'a3\'ba\'e1\'d7\'f8\'b1\'ea\'ba\'cd\'d7\'dd\'d7\'f8\'b1\'ea\'b7\'d6\'b1\'f0\'b6\'d4\'d3\'a6
\f1  gamma 
\f0 \'ba\'cd
\f1  sigma^2 
\f0 \'b5\'c4\'d6\'b5\'a3\'ac\'c3\'bf\'b8\'f6\'b5\'e3\'b5\'c4\'d1\'d5\'c9\'ab\'b1\'ed\'ca\'be\'ca\'b9\'d3\'c3\'d5\'e2\'d0\'a9\'d6\'b5\'ca\'b1\'c4\'a3\'d0\'cd\'b5\'c4\'d7\'bc\'c8\'b7\'b6\'c8\'a1\'a3\'d5\'e2\'b8\'f6\'cd\'bc\'b1\'ed\'bf\'c9\'d2\'d4\'b0\'ef\'d6\'fa\'ce\'d2\'c3\'c7\'c8\'b7\'b6\'a8\'d7\'ee\'bc\'d1\'b5\'c4
\f1  gamma 
\f0 \'ba\'cd
\f1  sigma^2 
\f0 \'d6\'b5\'a3\'ac\'d2\'d4\'b4\'ef\'b5\'bd\'d7\'ee\'b8\'df\'b5\'c4\'b7\'d6\'c0\'e0\'d7\'bc\'c8\'b7\'b6\'c8\'a1\'a3\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa266\partightenfactor0
\ls8\ilvl0
\f2\fs26\fsmilli13333 \cf4 \cb1 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Why should one prefer crossvalidation over simple validation (random split)? How to choose the value of k in k-fold crossvalidation? \uc0\u8232 
\f0\fs32 \cf2 \cb3 \
\pard\pardeftab720\partightenfactor0
\cf2 \
\pard\pardeftab720\sa400\partightenfactor0

\f1 \cf2 Cross-validation is generally preferred over simple validation (random split) because it provides a more reliable estimate of model performance. When using a random split, the model performance can vary depending on which data points are selected for the training and testing sets. Cross-validation, on the other hand, uses all the data for training and testing and provides an average performance estimate over multiple iterations. This makes the estimate less dependent on the particular split of the data.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 The choice of k in k-fold cross-validation depends on the size of the dataset and the computational resources available. A common choice is k=10, which is computationally efficient and provides a reasonable estimate of model performance. However, for smaller datasets, leave-one-out cross-validation (k=n, where n is the number of data points) may be used for a more accurate estimate, although it can be computationally expensive. For very large datasets, a smaller k may be used to reduce the computational cost, but this may result in a less reliable estimate of model performance.
\f0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f2\fs26\fsmilli13333 \cf4 \cb1 1.3.3 Automatic parameter tuning \
\pard\pardeftab720\sa240\partightenfactor0
\cf4 \'95 Try out the different \cf6 \'92algorithm\'92\cf4 . What differences do you observe? Why do the obtained hyperparameters differ a lot in different runs? What about the cost? Com- putational speed? Explain the results. 
\fs24 \
\pard\pardeftab720\sa240\partightenfactor0
\cf4 \
\pard\pardeftab720\partightenfactor0

\f0\fs32 \cf2 \cb3 \
\pard\pardeftab720\sa240\partightenfactor0

\f2\fs26\fsmilli13333 \cf4 \cb1 1.3.4 Using ROC curves 
\fs24 \
\pard\pardeftab720\sa240\partightenfactor0

\f3 \cf4 \'d3\'d0\'c1\'bd\'d5\'c5\'cd\'bc
\f2  Q1341 Q134
\f0\fs32 \cf2 \cb3 \
\pard\pardeftab720\partightenfactor0

\fs18 \cf2 \
 1. Coupled Simulated Annealing results:  [gam]         14518.8584\
                                          [sig2]        1.5962\
                                          F(X)=         0.03\
 \
 TUNELSSVM: chosen specifications:\
 2. optimization routine:           simplex\
    cost function:                  crossvalidatelssvm\
    kernel function                 RBF_kernel\
 \
\
 3. starting values:                   14518.8584      1.59617908\
\
 Iteration   Func-count    min f(x)    log(gamma)    log(sig2)    Procedure\
\
     1           3     3.000000e-02     10.7832        0.4676      initial \
     2           5     3.000000e-02     10.7832        0.4676      contract outside \
optimisation terminated sucessfully (TolFun criterion)\
\
Simplex results: \
X=48204.307389   1.596179, F(X)=3.000000e-02 \
\
Obtained hyper-parameters: [gamma sig2]: 48204.3074      1.59617908\
\
\pard\pardeftab720\partightenfactor0

\fs32 \cf2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls9\ilvl0
\f2\fs26\fsmilli13333 \cf4 \cb1 \kerning1\expnd0\expndtw0 {\listtext	.	}\expnd0\expndtw0\kerning0
1.3.5 Bayesian framework 
\fs24  
\f3\fs26\fsmilli13333 \'cd\'bc\'c6\'ac
\f2\fs24 Q135
\f0\fs32 \cf2 \cb3 \
\pard\pardeftab720\partightenfactor0
\cf2 \'b9\'db\'b2\'ec\'b7\'bd\'b7\'a8\'a3\'ba\
\pard\pardeftab720\sa400\partightenfactor0

\f1 \cf2 The above code will generate a figure showing the probability estimates for each data point in the training set. The colors in the plot represent the probability that a data point belongs to the positive class, with blue indicating low probability and red indicating high probability. The colorbar of the figure can be activated by clicking on the "Colorbar" button in the figure window.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 By changing the values of gam and sig2, you can observe the influence of these parameters on the probability estimates. In general, larger values of gam and smaller values of sig2 lead to more confident predictions, with higher probabilities for positive class points and lower probabilities for negative class points. Conversely, smaller values of gam and larger values of sig2 lead to less confident predictions, with more overlap between the probability distributions for the two classes.\
\
\pard\pardeftab720\sa240\partightenfactor0

\f2\fs37\fsmilli18667 \cf4 \cb1 2 Homework problems 
\fs24 \
\pard\pardeftab720\sa240\partightenfactor0

\fs26\fsmilli13333 \cf4 Illustrate your skills on support vector machine learning of synthetic and real-life datasets: 1. the Ripley dataset (ripley.mat),\uc0\u8232 2. the Wisconsin Breast Cancer dataset (breast.mat) and\u8232 3. the Diabetes dataset (diabetes.mat). 
\fs24 \

\fs26\fsmilli13333 All datasets are available on Toledo. More information regarding these datasets can be found on the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/index.php. For each of these datasets, answer the following questions related to LS-SVM classification. 
\fs24 \
\pard\pardeftab720\sa240\partightenfactor0

\fs26\fsmilli13333 \cf4 \cb5 Questions 
\fs24 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa266\partightenfactor0
\ls10\ilvl0
\fs26\fsmilli13333 \cf4 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Visualize the data. Inspect the data structure: what seems to be important prop- erties of the data? Which classification model do you think you need, based on the complexity of the data? \uc0\u8232 Q211 212
\f3  213
\f2 \
\ls10\ilvl0\kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Try out different models (linear, polynomial, RBF kernel) with tuned hyperparameter and kernel parameters. Compute the ROC curves. Which model performs best? Which model would you choose? \uc0\u8232 \
\pard\tx566\pardeftab720\sa266\partightenfactor0
\cf4 Q211 2-21 2-22 2-23\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa266\partightenfactor0
\ls11\ilvl0\cf4 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Are you satisfied with the performance of your model? Would you advise another methodology? \uc0\u8232 \
}